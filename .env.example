# RAG Chat API Environment Configuration
# Copy this file to .env and configure your values

# ===========================================
# REQUIRED CONFIGURATION
# ===========================================

# Server Configuration
NODE_ENV=development
PORT=3000

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# ===========================================
# DATABASE CONFIGURATION (Choose One)
# ===========================================

# Option 1: Neon Database (Recommended for production)
DATABASE_URL=postgresql://username:password@ep-xxx-xxx.us-east-2.aws.neon.tech/neondb?sslmode=require

# Option 2: Local PostgreSQL
# DATABASE_URL=postgresql://user:password@localhost:5432/ragchat

# Individual connection parameters (if not using DATABASE_URL)
DATABASE_HOST=ep-xxx-xxx.us-east-2.aws.neon.tech
DATABASE_PORT=5432
DATABASE_USER=username
DATABASE_PASSWORD=your_password_here
DATABASE_NAME=neondb
DATABASE_SSL=true

# ===========================================
# VECTOR STORE CONFIGURATION
# ===========================================

# Vector Store Configuration
VECTOR_TABLE_NAME=langchain_pg_embedding
VECTOR_COLLECTION_NAME=documents
VECTOR_DIMENSIONS=1536
USE_MEMORY_FALLBACK=true

# ===========================================
# FILE STORAGE CONFIGURATION
# ===========================================

# Blob Storage Configuration (Production)
BLOB_READ_WRITE_TOKEN=your_blob_token_here
BLOB_STORE_NAME=rag-chat-api-blob

# ===========================================
# OPTIONAL CONFIGURATION
# ===========================================

# Rate Limiting
RATE_LIMIT_WINDOW=15
RATE_LIMIT_MAX=100

# Security
CORS_ORIGIN=http://localhost:3000

# Logging
LOG_LEVEL=info

# Debug Mode
DEBUG=false

# ===========================================
# AI MODEL CONFIGURATION
# ===========================================

# OpenAI Embedding Model
EMBEDDING_MODEL=text-embedding-3-small
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002

# Chat Model
CHAT_MODEL=gpt-3.5-turbo
# Options: gpt-3.5-turbo, gpt-4, gpt-4-turbo

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# ===========================================
# PERFORMANCE TUNING
# ===========================================

# Vector Search Configuration
MAX_SEARCH_RESULTS=5
SIMILARITY_THRESHOLD=0.7

# File Upload Limits
MAX_FILE_SIZE=10485760
# 10MB in bytes

# Memory Limits
MAX_MEMORY_DOCUMENTS=100


# CORS Configuration
CORS_ORIGIN=http://localhost:3000
FRONTEND_URL=https://your-frontend-domain.com
OPENAI_MODEL=gpt-4
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=1000
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# For production with persistent storage (optional)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=your-s3-bucket

# For production with Pinecone (optional)
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX=your_pinecone_index
